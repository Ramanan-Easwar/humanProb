{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ ME\n",
    "* In this approach, I've created a list with all the keypoints from the tracker results in one list i.e. id_samples\n",
    "* The corresponding labels list is a boolean list of humans or not.\n",
    "\n",
    "# Approach\n",
    "* It is a very simple approach where the video is manually referred for a cutoff frame or a cutoff timestamp where there are no humans present in the video. Refering to the video in data/mf4f5 folder, after the timestamp of 42180s i.e. 11:40:00 humans appearance is drastically reduced yet the tracker gives ouputs for various elements. Thus, any element that is keyed by ID (concated.ndjson) that contains the timestamp beyond the range of cutoff timestamps(can be trained better with assigning proper ranges of this region where humans do not appear to improve efficiency) or contains any timestamp in this region of time where there are no humans, we take the tracker results in list containing 18 keypoints(by OpenPose COCO model) and feed it to a Neural Network.\n",
    "* Now, the neural network gets an input of (18,3) i.e. 18 keypoints with each returning a list [x,y,p(x)]. This is fed to a RNN and let the neural network handle the classification.\n",
    "* It then returns a result set for each element keyed by ID where key[n][0] tells us the probability whether it is indeed a human or not.\n",
    "\n",
    "\n",
    "\n",
    "# Steps\n",
    "* The timestamp ranges are noted where there are no humans and the split is made accordingly.\n",
    "* Then the list is converted to a numpy array and both the arrays are shuffled without losing their relationship using the shuffle() that uses seed method of rand_state. The import step here is not to lose the relationship between both the arrays or else there's no point in training the neural net. \n",
    "* Next, the test train split is done and the RNN is used with 3 LSTM layers(CuDNNLSTM) for the processing of 18 keypoints with each in a list of [x,y,p(x,y)] format and two dense layers to make the prediction.\n",
    "* For further details, refer the model.summary() cell which include the number of neurons per each layer. All the layers are of tf.keras\n",
    "* The result is in a 2 dimensional array where result[i][0] is the probability that it's a human and result[i][1] is the probability that it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening tracker results on data/mf4f5\n",
    "with open('concated.ndjson') as f:\n",
    "    c_data = ndjson.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the given ndjson file's format i.e. the Tracker Results \n",
    "  # (for reference of the tracker results-rough work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_data:\n",
    "    val = (int)(c['id'])\n",
    "    if(val == 0):\n",
    "        for i in range(18):\n",
    "            num = (c['frames'][0]['pose']['keypoints'][i]) #returns the 18 pose keypoints for 0th frame\n",
    "            #num = (c['frames'][0]['pose']) # returns the keypoints along with the midpoint of feet\n",
    "            print(num)\n",
    "        break\n",
    "for c in c_data:\n",
    "    val = (int)(c['id'])\n",
    "    if(val == 3124):\n",
    "        num = len(c['frames'])\n",
    "        for i in range(num):\n",
    "#             print(\"Frame: \",i,c['frames'][i]['position'])#frame by frame position of midpoint\n",
    "            print(\"Frame: \",i,c['frames'][i]['pose'])\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frames that don't have any humans are referred from video and is split accordingly. \n",
    "* In the context of the video, it is quite clear that there are no humans after a point of time in video. Yet, the tracker and the openpose results show the opposite. Thus, any object that has the timestamp value above 42698s i.e. beyond the 11 hours and 30 minute mark, we mark that id from the tracker result as non-human, that is, append a 0 to the label list along with it's keypoints in the sample list.\n",
    "* We do the same process for humans, except we append a 1 to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sample = [] #contains the keypoints along \n",
    "id_label = []  #human or not\n",
    "cutoff = 42180 #corresponds to the timestamp 11:40:00 in seconds\n",
    "for c in c_data:\n",
    "    num = len(c['frames'])\n",
    "    for i in range(num):\n",
    "        time = c['frames'][i]['timestamp']\n",
    "        time = int(time)\n",
<<<<<<< HEAD
    "        if(time >= cutoff): #timestamp where the humans stop appearing in seconds\n",
=======
    "        if(time >= 42180):  #change it to your correspoding timestamp where humans stop appearing\n" ,
>>>>>>> 76c9a295dffc899566693df11da19b24e15d3943
    "            li = c['frames'][i]['pose']['keypoints']\n",
    "            id_sample.append(li)\n",
    "            id_label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_data:\n",
    "    num = len(c['frames'])\n",
    "    for i in range(num):\n",
    "        time = c['frames'][i]['timestamp']\n",
    "        time = int(time)\n",
    "        if(time < cutoff): #timestamp where the humans stop appearing in seconds\n",
    "            li = c['frames'][i]['pose']['keypoints']\n",
    "            id_sample.append(li)\n",
    "            id_label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the lists into a numpy array for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample array containing keypoints of tracker (479319, 18, 3)\n",
      "Shape of sample array containing keypoints of tracker (479319,)\n"
     ]
    }
   ],
   "source": [
    "id_sample = np.array(id_sample)\n",
    "id_label = np.array(id_label)\n",
    "print(\"Shape of sample array containing keypoints of tracker\",id_sample.shape)\n",
    "print(\"Shape of sample array containing keypoints of tracker\",id_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle both the numpy arrays\n",
    "* Shuffling is done in such a way that the corresponding array elements continues to correspond, i.e. shuffle them in unison with respect to their leading indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(a, b, seed):\n",
    "   rand_state = np.random.RandomState(seed)\n",
    "   rand_state.shuffle(a)\n",
    "   rand_state.seed(seed)\n",
    "   rand_state.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(id_sample,id_label,12345) #Sample seed is 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION OF THE np ARRAY\n",
    "* the most essential step- normalize the data to improve efficiency of neural net.\n",
    "* After that, we split the data set into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for i in range(len(id_sample)):\n",
    "    id_sample[i] = scaler.fit_transform(id_sample[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(id_sample,id_label,test_size = 0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN DEFINITION\n",
    "* The RNN takes in the normalized train data and makes it run through 3 LSTM with dropouts to train it.\n",
    "* CuDNNLSTM is used to utilize the GPU and make the process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential,model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(128,input_shape = (18,3), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(CuDNNLSTM(128,input_shape = (18,3), return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(CuDNNLSTM(128,input_shape = (18,3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 18, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 18, 128)           512       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 18, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 18, 128)           512       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 338,018\n",
      "Trainable params: 337,250\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyOp = Adam(lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=MyOp, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 10\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 383455 samples, validate on 95864 samples\n",
      "Epoch 1/10\n",
      "383455/383455 [==============================] - 65s 170us/sample - loss: 0.5765 - accuracy: 0.7325 - val_loss: 0.5673 - val_accuracy: 0.7337\n",
      "Epoch 2/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5650 - accuracy: 0.7369 - val_loss: 0.5803 - val_accuracy: 0.7365\n",
      "Epoch 3/10\n",
      "383455/383455 [==============================] - 53s 139us/sample - loss: 0.5584 - accuracy: 0.7399 - val_loss: 0.5582 - val_accuracy: 0.7404\n",
      "Epoch 4/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5551 - accuracy: 0.7411 - val_loss: 0.5527 - val_accuracy: 0.7409\n",
      "Epoch 5/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5524 - accuracy: 0.7419 - val_loss: 0.5522 - val_accuracy: 0.7415\n",
      "Epoch 6/10\n",
      "383455/383455 [==============================] - 53s 139us/sample - loss: 0.5498 - accuracy: 0.7429 - val_loss: 0.5488 - val_accuracy: 0.7437\n",
      "Epoch 7/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5470 - accuracy: 0.7441 - val_loss: 0.5460 - val_accuracy: 0.7439\n",
      "Epoch 8/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5444 - accuracy: 0.7452 - val_loss: 0.5533 - val_accuracy: 0.7433\n",
      "Epoch 9/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5425 - accuracy: 0.7462 - val_loss: 0.5470 - val_accuracy: 0.7422\n",
      "Epoch 10/10\n",
      "383455/383455 [==============================] - 53s 138us/sample - loss: 0.5404 - accuracy: 0.7468 - val_loss: 0.5373 - val_accuracy: 0.7482\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, batch_size = bs, epochs = ep, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write sucessful!\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Write sucessful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/user/Workspace/data/mcc10/concated-keypoints.ndjson') as f:\n",
    "    val_data = ndjson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(time):\n",
    "    return (time * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = get_frame(1800) #for 30 minutes of footage. Please enter time in seconds. Calibrated to validation video's fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "p = val_data\n",
    "results = []\n",
    "x_val = []\n",
    "while(i < total_frames): #for the first 100 frames\n",
    "    person_count = len(p[i]['people'])\n",
    "    for j in range(person_count):\n",
    "        person = []\n",
    "        for k in range(18):\n",
    "            xyz = []\n",
    "            xyz.append(p[i]['people'][j]['pose_keypoints'][k])\n",
    "            xyz.append(p[i]['people'][j]['pose_keypoints'][k+1])\n",
    "            xyz.append(p[i]['people'][j]['pose_keypoints'][k+2])\n",
    "            person.append(xyz)\n",
    "        x_val.append(person)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70068, 18, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.array(x_val)\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_val) #results[n][0] --> probablity of the element being a human\n",
    "res = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('/home/user/Workspace/data/mcc10/concated.mp4')\n",
    "fp = 0\n",
    "d = val_data\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed\")\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "print(\"Starting validation...\")\n",
    "out = cv2.VideoWriter('validate_30.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "while(fp < total_frames):\n",
    "    person_count = len(d[fp]['people'])\n",
    "    i = 0\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    while(i < person_count):\n",
    "        x1.append(int(d[fp]['people'][i]['pose_keypoints'][0] - 5))\n",
    "        y1.append(int(d[fp]['people'][i]['pose_keypoints'][1] + 5))\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    if ret == True:\n",
    "        \n",
    "        i = 0\n",
    "        while(i < person_count):\n",
    "            ind = i\n",
    "            text1 =  str(ind)\n",
    "            results[res][0] = round(results[res][0],2)\n",
    "            text2 = \"P:\" + str(results[res][0])\n",
    "            font1 = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font2 = cv2.FONT_HERSHEY_PLAIN = 1\n",
    "            if(results[res][0] > 0.55):    #To print only confident results\n",
    "                cv2.putText(frame, text2, (x1[i]+3, y1[i]-2), font1, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, text1, (x1[i], y1[i]+2), font2, 0.5, (255, 255, 0), 0)\n",
    "                \n",
    "            i += 1\n",
    "            res += 1\n",
    "        \n",
    "    \n",
    "        out.write(frame)\n",
    "        fp += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    " \n",
    "cv2.destroyAllWindows() \n",
    "print(\"Finished validation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
